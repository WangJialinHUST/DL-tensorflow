{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 本例程是利用lstm搭建的recurrent neural network来对imdb电影评论数据进行分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# max total num of words\n",
    "max_features = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils import imdb\n",
    "from utils import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n",
      "25000 train sequences\n",
      "25000 test sequences\n"
     ]
    }
   ],
   "source": [
    "print('loading data')\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=max_features)\n",
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_test), 'test sequences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq_len = map(lambda x: len(x), X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218\n"
     ]
    }
   ],
   "source": [
    "print(seq_len[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218\n",
      "189\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train[0]))\n",
    "print(len(X_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "maxlen = 400\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 400)\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    1   14   22   16   43  530  973 1622 1385   65  458 4468   66\n",
      " 3941    4  173   36  256    5   25  100   43  838  112   50  670    2    9\n",
      "   35  480  284    5  150    4  172  112  167    2  336  385   39    4  172\n",
      " 4536 1111   17  546   38   13  447    4  192   50   16    6  147 2025   19\n",
      "   14   22    4 1920 4613  469    4   22   71   87   12   16   43  530   38\n",
      "   76   15   13 1247    4   22   17  515   17   12   16  626   18    2    5\n",
      "   62  386   12    8  316    8  106    5    4 2223    2   16  480   66 3785\n",
      "   33    4  130   12   16   38  619    5   25  124   51   36  135   48   25\n",
      " 1415   33    6   22   12  215   28   77   52    5   14  407   16   82    2\n",
      "    8    4  107  117    2   15  256    4    2    7 3766    5  723   36   71\n",
      "   43  530  476   26  400  317   46    7    4    2 1029   13  104   88    4\n",
      "  381   15  297   98   32 2071   56   26  141    6  194    2   18    4  226\n",
      "   22   21  134  476   26  480    5  144   30    2   18   51   36   28  224\n",
      "   92   25  104    4  226   65   16   38 1334   88   12   16  283    5   16\n",
      " 4472  113  103   32   15   16    2   19  178   32]\n"
     ]
    }
   ],
   "source": [
    "# left padding with right align\n",
    "print(X_train.shape)\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build the graph functions\n",
    "# add the placeholders\n",
    "def add_placeholders():\n",
    "    input_placeholder = tf.placeholder(tf.int32, shape=[batch_size, num_steps])\n",
    "    label_placeholder = tf.placeholder(tf.float32, shape=[batch_size])\n",
    "    \n",
    "    return input_placeholder, label_placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create the feed_dict\n",
    "def create_feed_dict(input_placeholder, input_batch, label_placeholder, label_batch):\n",
    "    feed_dict = {input_placeholder: input_batch,\n",
    "                label_placeholder:label_batch}\n",
    "    return feed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_embed_layer(vocab_size, input_placeholder):\n",
    "    with tf.device('/cpu:0'):\n",
    "        embed = tf.get_variable(name=\"Embedding\", shape=[vocab_size, embed_size])\n",
    "        inputs = tf.nn.embedding_lookup(embed, input_placeholder)\n",
    "        #inputs = [tf.squeeze(input, squeeze_dims=[1]) for input in tf.split(1, num_steps, inputs)]\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## add training op\n",
    "def add_train_op(loss):\n",
    "    train_op = tf.train.AdamOptimizer(0.001).minimize(loss)\n",
    "    return train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## add rnn model\n",
    "def add_rnn_model(hidden_size, num_steps):\n",
    "    lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(hidden_size, forget_bias=0.0)\n",
    "    #cell = tf.nn.rnn_cell.MultiRNNCell([lstm_cell]*num_steps)\n",
    "    cell = lstm_cell\n",
    "    return cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# evalate the prediction \n",
    "def evaluation(y_pred_sigmoid, label_placeholder):\n",
    "    y_pred_label = (y_pred_sigmoid > 0.5)\n",
    "    label_placeholder = tf.cast(label_placeholder, tf.bool)\n",
    "    correct_pred_num = []\n",
    "    correct_pred_num.append(tf.reduce_sum(tf.cast(tf.equal(y_pred_label, label_placeholder), tf.int32)))\n",
    "    correct_pred_num = np.sum(correct_pred_num)\n",
    "    return correct_pred_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_evaluation(sess, X, y):\n",
    "    total_correct_num = 0\n",
    "    num_steps = len(X) // batch_size\n",
    "    for step in range(num_steps):\n",
    "        # generate the data feed dict\n",
    "        input_batch = X[step*batch_size:(step+1)*batch_size, :]\n",
    "        label_batch = y[step*batch_size:(step+1)*batch_size]\n",
    "\n",
    "        feed = {input_placeholder:input_batch, label_placeholder:label_batch }\n",
    "        correct_num_step = sess.run([correct_num], feed)\n",
    "        total_correct_num += correct_num_step[0]\n",
    "    print('Testing Accuracy: %f' %(total_correct_num/(num_steps*batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#when debug set max_epochs = 1\n",
    "max_epochs = 15\n",
    "batch_size = 20\n",
    "hidden_size = 100\n",
    "num_steps = maxlen\n",
    "embed_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the majority classifier accuracy is 0.500000\n"
     ]
    }
   ],
   "source": [
    "# majority classfier\n",
    "majority = np.sum(y_train) / len(X_train)\n",
    "if majority > 0.5:\n",
    "    print('the majority classifier accuracy is %f' %(majority))\n",
    "else:\n",
    "    print('the majority classifier accuracy is %f' %(1-majority))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n",
      "12500\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "\n",
    "print(np.sum(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv1d(x, W):\n",
    "    return tf.nn.conv1d(x, W, stride=1, padding=\"SAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function conv1d in module tensorflow.python.ops.nn_ops:\n",
      "\n",
      "conv1d(value, filters, stride, padding, use_cudnn_on_gpu=None, data_format=None, name=None)\n",
      "    Computes a 1-D convolution given 3-D input and filter tensors.\n",
      "    \n",
      "    Given an input tensor of shape [batch, in_width, in_channels]\n",
      "    and a filter / kernel tensor of shape\n",
      "    [filter_width, in_channels, out_channels], this op reshapes\n",
      "    the arguments to pass them to conv2d to perform the equivalent\n",
      "    convolution operation.\n",
      "    \n",
      "    Internally, this op reshapes the input tensors and invokes\n",
      "    `tf.nn.conv2d`.  A tensor of shape [batch, in_width, in_channels]\n",
      "    is reshaped to [batch, 1, in_width, in_channels], and the filter\n",
      "    is reshaped to [1, filter_width, in_channels, out_channels].\n",
      "    The result is then reshaped back to [batch, out_width, out_channels]\n",
      "    (where out_width is a function of the stride and padding as in\n",
      "    conv2d) and returned to the caller.\n",
      "    \n",
      "    Args:\n",
      "      value: A 3D `Tensor`.  Must be of type `float32` or `float64`.\n",
      "      filters: A 3D `Tensor`.  Must have the same type as `input`.\n",
      "      stride: An `integer`.  The number of entries by which\n",
      "        the filter is moved right at each step.\n",
      "      padding: 'SAME' or 'VALID'\n",
      "      use_cudnn_on_gpu: An optional `bool`.  Defaults to `True`.\n",
      "      data_format: An optional `string` from `\"NHWC\", \"NCHW\"`.  Defaults\n",
      "        to `\"NHWC\"`, the data is stored in the order of\n",
      "        [batch, in_width, in_channels].  The `\"NCHW\"` format stores\n",
      "        data as [batch, in_channels, in_width].\n",
      "      name: A name for the operation (optional).\n",
      "    \n",
      "    Returns:\n",
      "      A `Tensor`.  Has the same type as input.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.nn.conv1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## the tf lib not contain the max_pool1d,\n",
    "## we can add one dummy dimension in the input tensor\n",
    "## x should be [batch_size, height, width, channels]\n",
    "## x : [batch_size, height, channels]\n",
    "## => [batch_size, height, channels, 1]\n",
    "## => [batch_size, height, 1, channels]\n",
    "def max_pool1d(x):\n",
    "    x = tf.expand_dims(x, -1)\n",
    "    x = tf.transpose(x,perm=[0,1,3,2]) ##\n",
    "    ## invoke maxpool\n",
    "    pool_out = tf.nn.max_pool(x, ksize=[1,2,1,1], strides=[1,4,1,1], padding=\"SAME\")\n",
    "    #pool_out = tf.transpose(pool_out,perm=[0,2,1,3])\n",
    "    pool_out = tf.squeeze(x, squeeze_dims=[2])\n",
    "    return pool_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module tensorflow.python.ops.rnn_cell in tensorflow.python.ops:\n",
      "\n",
      "NAME\n",
      "    tensorflow.python.ops.rnn_cell - Module for constructing RNN Cells.\n",
      "\n",
      "FILE\n",
      "    /home/wang/tensorflow_dl/local/lib/python2.7/site-packages/tensorflow/python/ops/rnn_cell.py\n",
      "\n",
      "DESCRIPTION\n",
      "    ## Base interface for all RNN Cells\n",
      "    \n",
      "    @@RNNCell\n",
      "    \n",
      "    ## RNN Cells for use with TensorFlow's core RNN methods\n",
      "    \n",
      "    @@BasicRNNCell\n",
      "    @@BasicLSTMCell\n",
      "    @@GRUCell\n",
      "    @@LSTMCell\n",
      "    \n",
      "    ## Classes storing split `RNNCell` state\n",
      "    \n",
      "    @@LSTMStateTuple\n",
      "    \n",
      "    ## RNN Cell wrappers (RNNCells that wrap other RNNCells)\n",
      "    \n",
      "    @@MultiRNNCell\n",
      "    @@DropoutWrapper\n",
      "    @@EmbeddingWrapper\n",
      "    @@InputProjectionWrapper\n",
      "    @@OutputProjectionWrapper\n",
      "\n",
      "CLASSES\n",
      "    __builtin__.object\n",
      "        RNNCell\n",
      "            BasicLSTMCell\n",
      "            BasicRNNCell\n",
      "            DropoutWrapper\n",
      "            EmbeddingWrapper\n",
      "            GRUCell\n",
      "            InputProjectionWrapper\n",
      "            LSTMCell\n",
      "            MultiRNNCell\n",
      "            OutputProjectionWrapper\n",
      "    LSTMStateTuple(__builtin__.tuple)\n",
      "        LSTMStateTuple\n",
      "    \n",
      "    class BasicLSTMCell(RNNCell)\n",
      "     |  Basic LSTM recurrent network cell.\n",
      "     |  \n",
      "     |  The implementation is based on: http://arxiv.org/abs/1409.2329.\n",
      "     |  \n",
      "     |  We add forget_bias (default: 1) to the biases of the forget gate in order to\n",
      "     |  reduce the scale of forgetting in the beginning of the training.\n",
      "     |  \n",
      "     |  It does not allow cell clipping, a projection layer, and does not\n",
      "     |  use peep-hole connections: it is the basic baseline.\n",
      "     |  \n",
      "     |  For advanced models, please use the full LSTMCell that follows.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      BasicLSTMCell\n",
      "     |      RNNCell\n",
      "     |      __builtin__.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self, inputs, state, scope=None)\n",
      "     |      Long short-term memory cell (LSTM).\n",
      "     |  \n",
      "     |  __init__(self, num_units, forget_bias=1.0, input_size=None, state_is_tuple=True, activation=<function tanh>)\n",
      "     |      Initialize the basic LSTM cell.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        num_units: int, The number of units in the LSTM cell.\n",
      "     |        forget_bias: float, The bias added to forget gates (see above).\n",
      "     |        input_size: Deprecated and unused.\n",
      "     |        state_is_tuple: If True, accepted and returned states are 2-tuples of\n",
      "     |          the `c_state` and `m_state`.  If False, they are concatenated\n",
      "     |          along the column axis.  The latter behavior will soon be deprecated.\n",
      "     |        activation: Activation function of the inner states.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  output_size\n",
      "     |  \n",
      "     |  state_size\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from RNNCell:\n",
      "     |  \n",
      "     |  zero_state(self, batch_size, dtype)\n",
      "     |      Return zero-filled state tensor(s).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        batch_size: int, float, or unit Tensor representing the batch size.\n",
      "     |        dtype: the data type to use for the state.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        If `state_size` is an int or TensorShape, then the return value is a\n",
      "     |        `N-D` tensor of shape `[batch_size x state_size]` filled with zeros.\n",
      "     |      \n",
      "     |        If `state_size` is a nested list or tuple, then the return value is\n",
      "     |        a nested list or tuple (of the same structure) of `2-D` tensors with\n",
      "     |      the shapes `[batch_size x s]` for each s in `state_size`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from RNNCell:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class BasicRNNCell(RNNCell)\n",
      "     |  The most basic RNN cell.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      BasicRNNCell\n",
      "     |      RNNCell\n",
      "     |      __builtin__.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self, inputs, state, scope=None)\n",
      "     |      Most basic RNN: output = new_state = activation(W * input + U * state + B).\n",
      "     |  \n",
      "     |  __init__(self, num_units, input_size=None, activation=<function tanh>)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  output_size\n",
      "     |  \n",
      "     |  state_size\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from RNNCell:\n",
      "     |  \n",
      "     |  zero_state(self, batch_size, dtype)\n",
      "     |      Return zero-filled state tensor(s).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        batch_size: int, float, or unit Tensor representing the batch size.\n",
      "     |        dtype: the data type to use for the state.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        If `state_size` is an int or TensorShape, then the return value is a\n",
      "     |        `N-D` tensor of shape `[batch_size x state_size]` filled with zeros.\n",
      "     |      \n",
      "     |        If `state_size` is a nested list or tuple, then the return value is\n",
      "     |        a nested list or tuple (of the same structure) of `2-D` tensors with\n",
      "     |      the shapes `[batch_size x s]` for each s in `state_size`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from RNNCell:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class DropoutWrapper(RNNCell)\n",
      "     |  Operator adding dropout to inputs and outputs of the given cell.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      DropoutWrapper\n",
      "     |      RNNCell\n",
      "     |      __builtin__.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self, inputs, state, scope=None)\n",
      "     |      Run the cell with the declared dropouts.\n",
      "     |  \n",
      "     |  __init__(self, cell, input_keep_prob=1.0, output_keep_prob=1.0, seed=None)\n",
      "     |      Create a cell with added input and/or output dropout.\n",
      "     |      \n",
      "     |      Dropout is never used on the state.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        cell: an RNNCell, a projection to output_size is added to it.\n",
      "     |        input_keep_prob: unit Tensor or float between 0 and 1, input keep\n",
      "     |          probability; if it is float and 1, no input dropout will be added.\n",
      "     |        output_keep_prob: unit Tensor or float between 0 and 1, output keep\n",
      "     |          probability; if it is float and 1, no output dropout will be added.\n",
      "     |        seed: (optional) integer, the randomness seed.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: if cell is not an RNNCell.\n",
      "     |        ValueError: if keep_prob is not between 0 and 1.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  output_size\n",
      "     |  \n",
      "     |  state_size\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from RNNCell:\n",
      "     |  \n",
      "     |  zero_state(self, batch_size, dtype)\n",
      "     |      Return zero-filled state tensor(s).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        batch_size: int, float, or unit Tensor representing the batch size.\n",
      "     |        dtype: the data type to use for the state.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        If `state_size` is an int or TensorShape, then the return value is a\n",
      "     |        `N-D` tensor of shape `[batch_size x state_size]` filled with zeros.\n",
      "     |      \n",
      "     |        If `state_size` is a nested list or tuple, then the return value is\n",
      "     |        a nested list or tuple (of the same structure) of `2-D` tensors with\n",
      "     |      the shapes `[batch_size x s]` for each s in `state_size`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from RNNCell:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class EmbeddingWrapper(RNNCell)\n",
      "     |  Operator adding input embedding to the given cell.\n",
      "     |  \n",
      "     |  Note: in many cases it may be more efficient to not use this wrapper,\n",
      "     |  but instead concatenate the whole sequence of your inputs in time,\n",
      "     |  do the embedding on this batch-concatenated sequence, then split it and\n",
      "     |  feed into your RNN.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      EmbeddingWrapper\n",
      "     |      RNNCell\n",
      "     |      __builtin__.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self, inputs, state, scope=None)\n",
      "     |      Run the cell on embedded inputs.\n",
      "     |  \n",
      "     |  __init__(self, cell, embedding_classes, embedding_size, initializer=None)\n",
      "     |      Create a cell with an added input embedding.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        cell: an RNNCell, an embedding will be put before its inputs.\n",
      "     |        embedding_classes: integer, how many symbols will be embedded.\n",
      "     |        embedding_size: integer, the size of the vectors we embed into.\n",
      "     |        initializer: an initializer to use when creating the embedding;\n",
      "     |          if None, the initializer from variable scope or a default one is used.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: if cell is not an RNNCell.\n",
      "     |        ValueError: if embedding_classes is not positive.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  output_size\n",
      "     |  \n",
      "     |  state_size\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from RNNCell:\n",
      "     |  \n",
      "     |  zero_state(self, batch_size, dtype)\n",
      "     |      Return zero-filled state tensor(s).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        batch_size: int, float, or unit Tensor representing the batch size.\n",
      "     |        dtype: the data type to use for the state.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        If `state_size` is an int or TensorShape, then the return value is a\n",
      "     |        `N-D` tensor of shape `[batch_size x state_size]` filled with zeros.\n",
      "     |      \n",
      "     |        If `state_size` is a nested list or tuple, then the return value is\n",
      "     |        a nested list or tuple (of the same structure) of `2-D` tensors with\n",
      "     |      the shapes `[batch_size x s]` for each s in `state_size`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from RNNCell:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class GRUCell(RNNCell)\n",
      "     |  Gated Recurrent Unit cell (cf. http://arxiv.org/abs/1406.1078).\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      GRUCell\n",
      "     |      RNNCell\n",
      "     |      __builtin__.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self, inputs, state, scope=None)\n",
      "     |      Gated recurrent unit (GRU) with nunits cells.\n",
      "     |  \n",
      "     |  __init__(self, num_units, input_size=None, activation=<function tanh>)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  output_size\n",
      "     |  \n",
      "     |  state_size\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from RNNCell:\n",
      "     |  \n",
      "     |  zero_state(self, batch_size, dtype)\n",
      "     |      Return zero-filled state tensor(s).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        batch_size: int, float, or unit Tensor representing the batch size.\n",
      "     |        dtype: the data type to use for the state.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        If `state_size` is an int or TensorShape, then the return value is a\n",
      "     |        `N-D` tensor of shape `[batch_size x state_size]` filled with zeros.\n",
      "     |      \n",
      "     |        If `state_size` is a nested list or tuple, then the return value is\n",
      "     |        a nested list or tuple (of the same structure) of `2-D` tensors with\n",
      "     |      the shapes `[batch_size x s]` for each s in `state_size`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from RNNCell:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class InputProjectionWrapper(RNNCell)\n",
      "     |  Operator adding an input projection to the given cell.\n",
      "     |  \n",
      "     |  Note: in many cases it may be more efficient to not use this wrapper,\n",
      "     |  but instead concatenate the whole sequence of your inputs in time,\n",
      "     |  do the projection on this batch-concatenated sequence, then split it.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      InputProjectionWrapper\n",
      "     |      RNNCell\n",
      "     |      __builtin__.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self, inputs, state, scope=None)\n",
      "     |      Run the input projection and then the cell.\n",
      "     |  \n",
      "     |  __init__(self, cell, num_proj, input_size=None)\n",
      "     |      Create a cell with input projection.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        cell: an RNNCell, a projection of inputs is added before it.\n",
      "     |        num_proj: Python integer.  The dimension to project to.\n",
      "     |        input_size: Deprecated and unused.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: if cell is not an RNNCell.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  output_size\n",
      "     |  \n",
      "     |  state_size\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from RNNCell:\n",
      "     |  \n",
      "     |  zero_state(self, batch_size, dtype)\n",
      "     |      Return zero-filled state tensor(s).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        batch_size: int, float, or unit Tensor representing the batch size.\n",
      "     |        dtype: the data type to use for the state.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        If `state_size` is an int or TensorShape, then the return value is a\n",
      "     |        `N-D` tensor of shape `[batch_size x state_size]` filled with zeros.\n",
      "     |      \n",
      "     |        If `state_size` is a nested list or tuple, then the return value is\n",
      "     |        a nested list or tuple (of the same structure) of `2-D` tensors with\n",
      "     |      the shapes `[batch_size x s]` for each s in `state_size`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from RNNCell:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class LSTMCell(RNNCell)\n",
      "     |  Long short-term memory unit (LSTM) recurrent network cell.\n",
      "     |  \n",
      "     |  The default non-peephole implementation is based on:\n",
      "     |  \n",
      "     |    http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf\n",
      "     |  \n",
      "     |  S. Hochreiter and J. Schmidhuber.\n",
      "     |  \"Long Short-Term Memory\". Neural Computation, 9(8):1735-1780, 1997.\n",
      "     |  \n",
      "     |  The peephole implementation is based on:\n",
      "     |  \n",
      "     |    https://research.google.com/pubs/archive/43905.pdf\n",
      "     |  \n",
      "     |  Hasim Sak, Andrew Senior, and Francoise Beaufays.\n",
      "     |  \"Long short-term memory recurrent neural network architectures for\n",
      "     |   large scale acoustic modeling.\" INTERSPEECH, 2014.\n",
      "     |  \n",
      "     |  The class uses optional peep-hole connections, optional cell clipping, and\n",
      "     |  an optional projection layer.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      LSTMCell\n",
      "     |      RNNCell\n",
      "     |      __builtin__.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self, inputs, state, scope=None)\n",
      "     |      Run one step of LSTM.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        inputs: input Tensor, 2D, batch x num_units.\n",
      "     |        state: if `state_is_tuple` is False, this must be a state Tensor,\n",
      "     |          `2-D, batch x state_size`.  If `state_is_tuple` is True, this must be a\n",
      "     |          tuple of state Tensors, both `2-D`, with column sizes `c_state` and\n",
      "     |          `m_state`.\n",
      "     |        scope: VariableScope for the created subgraph; defaults to \"LSTMCell\".\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A tuple containing:\n",
      "     |        - A `2-D, [batch x output_dim]`, Tensor representing the output of the\n",
      "     |          LSTM after reading `inputs` when previous state was `state`.\n",
      "     |          Here output_dim is:\n",
      "     |             num_proj if num_proj was set,\n",
      "     |             num_units otherwise.\n",
      "     |        - Tensor(s) representing the new state of LSTM after reading `inputs` when\n",
      "     |          the previous state was `state`.  Same type and shape(s) as `state`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If input size cannot be inferred from inputs via\n",
      "     |          static shape inference.\n",
      "     |  \n",
      "     |  __init__(self, num_units, input_size=None, use_peepholes=False, cell_clip=None, initializer=None, num_proj=None, proj_clip=None, num_unit_shards=1, num_proj_shards=1, forget_bias=1.0, state_is_tuple=True, activation=<function tanh>)\n",
      "     |      Initialize the parameters for an LSTM cell.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        num_units: int, The number of units in the LSTM cell\n",
      "     |        input_size: Deprecated and unused.\n",
      "     |        use_peepholes: bool, set True to enable diagonal/peephole connections.\n",
      "     |        cell_clip: (optional) A float value, if provided the cell state is clipped\n",
      "     |          by this value prior to the cell output activation.\n",
      "     |        initializer: (optional) The initializer to use for the weight and\n",
      "     |          projection matrices.\n",
      "     |        num_proj: (optional) int, The output dimensionality for the projection\n",
      "     |          matrices.  If None, no projection is performed.\n",
      "     |        proj_clip: (optional) A float value.  If `num_proj > 0` and `proj_clip` is\n",
      "     |        provided, then the projected values are clipped elementwise to within\n",
      "     |        `[-proj_clip, proj_clip]`.\n",
      "     |        num_unit_shards: How to split the weight matrix.  If >1, the weight\n",
      "     |          matrix is stored across num_unit_shards.\n",
      "     |        num_proj_shards: How to split the projection matrix.  If >1, the\n",
      "     |          projection matrix is stored across num_proj_shards.\n",
      "     |        forget_bias: Biases of the forget gate are initialized by default to 1\n",
      "     |          in order to reduce the scale of forgetting at the beginning of\n",
      "     |          the training.\n",
      "     |        state_is_tuple: If True, accepted and returned states are 2-tuples of\n",
      "     |          the `c_state` and `m_state`.  If False, they are concatenated\n",
      "     |          along the column axis.  This latter behavior will soon be deprecated.\n",
      "     |        activation: Activation function of the inner states.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  output_size\n",
      "     |  \n",
      "     |  state_size\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from RNNCell:\n",
      "     |  \n",
      "     |  zero_state(self, batch_size, dtype)\n",
      "     |      Return zero-filled state tensor(s).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        batch_size: int, float, or unit Tensor representing the batch size.\n",
      "     |        dtype: the data type to use for the state.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        If `state_size` is an int or TensorShape, then the return value is a\n",
      "     |        `N-D` tensor of shape `[batch_size x state_size]` filled with zeros.\n",
      "     |      \n",
      "     |        If `state_size` is a nested list or tuple, then the return value is\n",
      "     |        a nested list or tuple (of the same structure) of `2-D` tensors with\n",
      "     |      the shapes `[batch_size x s]` for each s in `state_size`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from RNNCell:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class LSTMStateTuple(LSTMStateTuple)\n",
      "     |  Tuple used by LSTM Cells for `state_size`, `zero_state`, and output state.\n",
      "     |  \n",
      "     |  Stores two elements: `(c, h)`, in that order.\n",
      "     |  \n",
      "     |  Only used when `state_is_tuple=True`.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      LSTMStateTuple\n",
      "     |      LSTMStateTuple\n",
      "     |      __builtin__.tuple\n",
      "     |      __builtin__.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  dtype\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from LSTMStateTuple:\n",
      "     |  \n",
      "     |  __getnewargs__(self)\n",
      "     |      Return self as a plain tuple.  Used by copy and pickle.\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Exclude the OrderedDict from pickling\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return a nicely formatted representation string\n",
      "     |  \n",
      "     |  _asdict(self)\n",
      "     |      Return a new OrderedDict which maps field names to their values\n",
      "     |  \n",
      "     |  _replace(_self, **kwds)\n",
      "     |      Return a new LSTMStateTuple object replacing specified fields with new values\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from LSTMStateTuple:\n",
      "     |  \n",
      "     |  _make(cls, iterable, new=<built-in method __new__ of type object>, len=<built-in function len>) from __builtin__.type\n",
      "     |      Make a new LSTMStateTuple object from a sequence or iterable\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from LSTMStateTuple:\n",
      "     |  \n",
      "     |  __new__(_cls, c, h)\n",
      "     |      Create new instance of LSTMStateTuple(c, h)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from LSTMStateTuple:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      Return a new OrderedDict which maps field names to their values\n",
      "     |  \n",
      "     |  c\n",
      "     |      Alias for field number 0\n",
      "     |  \n",
      "     |  h\n",
      "     |      Alias for field number 1\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from LSTMStateTuple:\n",
      "     |  \n",
      "     |  _fields = ('c', 'h')\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from __builtin__.tuple:\n",
      "     |  \n",
      "     |  __add__(...)\n",
      "     |      x.__add__(y) <==> x+y\n",
      "     |  \n",
      "     |  __contains__(...)\n",
      "     |      x.__contains__(y) <==> y in x\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      x.__eq__(y) <==> x==y\n",
      "     |  \n",
      "     |  __ge__(...)\n",
      "     |      x.__ge__(y) <==> x>=y\n",
      "     |  \n",
      "     |  __getattribute__(...)\n",
      "     |      x.__getattribute__('name') <==> x.name\n",
      "     |  \n",
      "     |  __getitem__(...)\n",
      "     |      x.__getitem__(y) <==> x[y]\n",
      "     |  \n",
      "     |  __getslice__(...)\n",
      "     |      x.__getslice__(i, j) <==> x[i:j]\n",
      "     |      \n",
      "     |      Use of negative indices is not supported.\n",
      "     |  \n",
      "     |  __gt__(...)\n",
      "     |      x.__gt__(y) <==> x>y\n",
      "     |  \n",
      "     |  __hash__(...)\n",
      "     |      x.__hash__() <==> hash(x)\n",
      "     |  \n",
      "     |  __iter__(...)\n",
      "     |      x.__iter__() <==> iter(x)\n",
      "     |  \n",
      "     |  __le__(...)\n",
      "     |      x.__le__(y) <==> x<=y\n",
      "     |  \n",
      "     |  __len__(...)\n",
      "     |      x.__len__() <==> len(x)\n",
      "     |  \n",
      "     |  __lt__(...)\n",
      "     |      x.__lt__(y) <==> x<y\n",
      "     |  \n",
      "     |  __mul__(...)\n",
      "     |      x.__mul__(n) <==> x*n\n",
      "     |  \n",
      "     |  __ne__(...)\n",
      "     |      x.__ne__(y) <==> x!=y\n",
      "     |  \n",
      "     |  __rmul__(...)\n",
      "     |      x.__rmul__(n) <==> n*x\n",
      "     |  \n",
      "     |  count(...)\n",
      "     |      T.count(value) -> integer -- return number of occurrences of value\n",
      "     |  \n",
      "     |  index(...)\n",
      "     |      T.index(value, [start, [stop]]) -> integer -- return first index of value.\n",
      "     |      Raises ValueError if the value is not present.\n",
      "    \n",
      "    class MultiRNNCell(RNNCell)\n",
      "     |  RNN cell composed sequentially of multiple simple cells.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      MultiRNNCell\n",
      "     |      RNNCell\n",
      "     |      __builtin__.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self, inputs, state, scope=None)\n",
      "     |      Run this multi-layer cell on inputs, starting from state.\n",
      "     |  \n",
      "     |  __init__(self, cells, state_is_tuple=True)\n",
      "     |      Create a RNN cell composed sequentially of a number of RNNCells.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        cells: list of RNNCells that will be composed in this order.\n",
      "     |        state_is_tuple: If True, accepted and returned states are n-tuples, where\n",
      "     |          `n = len(cells)`.  If False, the states are all\n",
      "     |          concatenated along the column axis.  This latter behavior will soon be\n",
      "     |          deprecated.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: if cells is empty (not allowed), or at least one of the cells\n",
      "     |          returns a state tuple but the flag `state_is_tuple` is `False`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  output_size\n",
      "     |  \n",
      "     |  state_size\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from RNNCell:\n",
      "     |  \n",
      "     |  zero_state(self, batch_size, dtype)\n",
      "     |      Return zero-filled state tensor(s).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        batch_size: int, float, or unit Tensor representing the batch size.\n",
      "     |        dtype: the data type to use for the state.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        If `state_size` is an int or TensorShape, then the return value is a\n",
      "     |        `N-D` tensor of shape `[batch_size x state_size]` filled with zeros.\n",
      "     |      \n",
      "     |        If `state_size` is a nested list or tuple, then the return value is\n",
      "     |        a nested list or tuple (of the same structure) of `2-D` tensors with\n",
      "     |      the shapes `[batch_size x s]` for each s in `state_size`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from RNNCell:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class OutputProjectionWrapper(RNNCell)\n",
      "     |  Operator adding an output projection to the given cell.\n",
      "     |  \n",
      "     |  Note: in many cases it may be more efficient to not use this wrapper,\n",
      "     |  but instead concatenate the whole sequence of your outputs in time,\n",
      "     |  do the projection on this batch-concatenated sequence, then split it\n",
      "     |  if needed or directly feed into a softmax.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      OutputProjectionWrapper\n",
      "     |      RNNCell\n",
      "     |      __builtin__.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self, inputs, state, scope=None)\n",
      "     |      Run the cell and output projection on inputs, starting from state.\n",
      "     |  \n",
      "     |  __init__(self, cell, output_size)\n",
      "     |      Create a cell with output projection.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        cell: an RNNCell, a projection to output_size is added to it.\n",
      "     |        output_size: integer, the size of the output after projection.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: if cell is not an RNNCell.\n",
      "     |        ValueError: if output_size is not positive.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  output_size\n",
      "     |  \n",
      "     |  state_size\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from RNNCell:\n",
      "     |  \n",
      "     |  zero_state(self, batch_size, dtype)\n",
      "     |      Return zero-filled state tensor(s).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        batch_size: int, float, or unit Tensor representing the batch size.\n",
      "     |        dtype: the data type to use for the state.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        If `state_size` is an int or TensorShape, then the return value is a\n",
      "     |        `N-D` tensor of shape `[batch_size x state_size]` filled with zeros.\n",
      "     |      \n",
      "     |        If `state_size` is a nested list or tuple, then the return value is\n",
      "     |        a nested list or tuple (of the same structure) of `2-D` tensors with\n",
      "     |      the shapes `[batch_size x s]` for each s in `state_size`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from RNNCell:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class RNNCell(__builtin__.object)\n",
      "     |  Abstract object representing an RNN cell.\n",
      "     |  \n",
      "     |  The definition of cell in this package differs from the definition used in the\n",
      "     |  literature. In the literature, cell refers to an object with a single scalar\n",
      "     |  output. The definition in this package refers to a horizontal array of such\n",
      "     |  units.\n",
      "     |  \n",
      "     |  An RNN cell, in the most abstract setting, is anything that has\n",
      "     |  a state and performs some operation that takes a matrix of inputs.\n",
      "     |  This operation results in an output matrix with `self.output_size` columns.\n",
      "     |  If `self.state_size` is an integer, this operation also results in a new\n",
      "     |  state matrix with `self.state_size` columns.  If `self.state_size` is a\n",
      "     |  tuple of integers, then it results in a tuple of `len(state_size)` state\n",
      "     |  matrices, each with the a column size corresponding to values in `state_size`.\n",
      "     |  \n",
      "     |  This module provides a number of basic commonly used RNN cells, such as\n",
      "     |  LSTM (Long Short Term Memory) or GRU (Gated Recurrent Unit), and a number\n",
      "     |  of operators that allow add dropouts, projections, or embeddings for inputs.\n",
      "     |  Constructing multi-layer cells is supported by the class `MultiRNNCell`,\n",
      "     |  or by calling the `rnn` ops several times. Every `RNNCell` must have the\n",
      "     |  properties below and and implement `__call__` with the following signature.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self, inputs, state, scope=None)\n",
      "     |      Run this RNN cell on inputs, starting from the given state.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        inputs: `2-D` tensor with shape `[batch_size x input_size]`.\n",
      "     |        state: if `self.state_size` is an integer, this should be a `2-D Tensor`\n",
      "     |          with shape `[batch_size x self.state_size]`.  Otherwise, if\n",
      "     |          `self.state_size` is a tuple of integers, this should be a tuple\n",
      "     |          with shapes `[batch_size x s] for s in self.state_size`.\n",
      "     |        scope: VariableScope for the created subgraph; defaults to class name.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A pair containing:\n",
      "     |        - Output: A `2-D` tensor with shape `[batch_size x self.output_size]`.\n",
      "     |        - New state: Either a single `2-D` tensor, or a tuple of tensors matching\n",
      "     |          the arity and shapes of `state`.\n",
      "     |  \n",
      "     |  zero_state(self, batch_size, dtype)\n",
      "     |      Return zero-filled state tensor(s).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        batch_size: int, float, or unit Tensor representing the batch size.\n",
      "     |        dtype: the data type to use for the state.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        If `state_size` is an int or TensorShape, then the return value is a\n",
      "     |        `N-D` tensor of shape `[batch_size x state_size]` filled with zeros.\n",
      "     |      \n",
      "     |        If `state_size` is a nested list or tuple, then the return value is\n",
      "     |        a nested list or tuple (of the same structure) of `2-D` tensors with\n",
      "     |      the shapes `[batch_size x s]` for each s in `state_size`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  output_size\n",
      "     |      Integer or TensorShape: size of outputs produced by this cell.\n",
      "     |  \n",
      "     |  state_size\n",
      "     |      size(s) of state(s) used by this cell.\n",
      "     |      \n",
      "     |      It can be represented by an Integer, a TensorShape or a tuple of Integers\n",
      "     |      or TensorShapes.\n",
      "\n",
      "DATA\n",
      "    absolute_import = _Feature((2, 5, 0, 'alpha', 1), (3, 0, 0, 'alpha', 0...\n",
      "    division = _Feature((2, 2, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0), 8192...\n",
      "    print_function = _Feature((2, 6, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0)...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.nn.rnn_cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function dynamic_rnn in module tensorflow.python.ops.rnn:\n",
      "\n",
      "dynamic_rnn(cell, inputs, sequence_length=None, initial_state=None, dtype=None, parallel_iterations=None, swap_memory=False, time_major=False, scope=None)\n",
      "    Creates a recurrent neural network specified by RNNCell `cell`.\n",
      "    \n",
      "    This function is functionally identical to the function `rnn` above, but\n",
      "    performs fully dynamic unrolling of `inputs`.\n",
      "    \n",
      "    Unlike `rnn`, the input `inputs` is not a Python list of `Tensors`, one for\n",
      "    each frame.  Instead, `inputs` may be a single `Tensor` where\n",
      "    the maximum time is either the first or second dimension (see the parameter\n",
      "    `time_major`).  Alternatively, it may be a (possibly nested) tuple of\n",
      "    Tensors, each of them having matching batch and time dimensions.\n",
      "    The corresponding output is either a single `Tensor` having the same number\n",
      "    of time steps and batch size, or a (possibly nested) tuple of such tensors,\n",
      "    matching the nested structure of `cell.output_size`.\n",
      "    \n",
      "    The parameter `sequence_length` is optional and is used to copy-through state\n",
      "    and zero-out outputs when past a batch element's sequence length. So it's more\n",
      "    for correctness than performance, unlike in rnn().\n",
      "    \n",
      "    Args:\n",
      "      cell: An instance of RNNCell.\n",
      "      inputs: The RNN inputs.\n",
      "    \n",
      "        If `time_major == False` (default), this must be a `Tensor` of shape:\n",
      "          `[batch_size, max_time, ...]`, or a nested tuple of such\n",
      "          elements.\n",
      "    \n",
      "        If `time_major == True`, this must be a `Tensor` of shape:\n",
      "          `[max_time, batch_size, ...]`, or a nested tuple of such\n",
      "          elements.\n",
      "    \n",
      "        This may also be a (possibly nested) tuple of Tensors satisfying\n",
      "        this property.  The first two dimensions must match across all the inputs,\n",
      "        but otherwise the ranks and other shape components may differ.\n",
      "        In this case, input to `cell` at each time-step will replicate the\n",
      "        structure of these tuples, except for the time dimension (from which the\n",
      "        time is taken).\n",
      "    \n",
      "        The input to `cell` at each time step will be a `Tensor` or (possibly\n",
      "        nested) tuple of Tensors each with dimensions `[batch_size, ...]`.\n",
      "      sequence_length: (optional) An int32/int64 vector sized `[batch_size]`.\n",
      "      initial_state: (optional) An initial state for the RNN.\n",
      "        If `cell.state_size` is an integer, this must be\n",
      "        a `Tensor` of appropriate type and shape `[batch_size x cell.state_size]`.\n",
      "        If `cell.state_size` is a tuple, this should be a tuple of\n",
      "        tensors having shapes `[batch_size, s] for s in cell.state_size`.\n",
      "      dtype: (optional) The data type for the initial state and expected output.\n",
      "        Required if initial_state is not provided or RNN state has a heterogeneous\n",
      "        dtype.\n",
      "      parallel_iterations: (Default: 32).  The number of iterations to run in\n",
      "        parallel.  Those operations which do not have any temporal dependency\n",
      "        and can be run in parallel, will be.  This parameter trades off\n",
      "        time for space.  Values >> 1 use more memory but take less time,\n",
      "        while smaller values use less memory but computations take longer.\n",
      "      swap_memory: Transparently swap the tensors produced in forward inference\n",
      "        but needed for back prop from GPU to CPU.  This allows training RNNs\n",
      "        which would typically not fit on a single GPU, with very minimal (or no)\n",
      "        performance penalty.\n",
      "      time_major: The shape format of the `inputs` and `outputs` Tensors.\n",
      "        If true, these `Tensors` must be shaped `[max_time, batch_size, depth]`.\n",
      "        If false, these `Tensors` must be shaped `[batch_size, max_time, depth]`.\n",
      "        Using `time_major = True` is a bit more efficient because it avoids\n",
      "        transposes at the beginning and end of the RNN calculation.  However,\n",
      "        most TensorFlow data is batch-major, so by default this function\n",
      "        accepts input and emits output in batch-major form.\n",
      "      scope: VariableScope for the created subgraph; defaults to \"RNN\".\n",
      "    \n",
      "    Returns:\n",
      "      A pair (outputs, state) where:\n",
      "    \n",
      "        outputs: The RNN output `Tensor`.\n",
      "    \n",
      "          If time_major == False (default), this will be a `Tensor` shaped:\n",
      "            `[batch_size, max_time, cell.output_size]`.\n",
      "    \n",
      "          If time_major == True, this will be a `Tensor` shaped:\n",
      "            `[max_time, batch_size, cell.output_size]`.\n",
      "    \n",
      "          Note, if `cell.output_size` is a (possibly nested) tuple of integers\n",
      "          or `TensorShape` objects, then `outputs` will be a tuple having the\n",
      "          same structure as `cell.output_size`, containing Tensors having shapes\n",
      "          corresponding to the shape data in `cell.output_size`.\n",
      "    \n",
      "        state: The final state.  If `cell.state_size` is an int, this\n",
      "          will be shaped `[batch_size, cell.state_size]`.  If it is a\n",
      "          `TensorShape`, this will be shaped `[batch_size] + cell.state_size`.\n",
      "          If it is a (possibly nested) tuple of ints or `TensorShape`, this will\n",
      "          be a tuple having the corresponding shapes.\n",
      "    \n",
      "    Raises:\n",
      "      TypeError: If `cell` is not an instance of RNNCell.\n",
      "      ValueError: If inputs is None or an empty list.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.nn.dynamic_rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function concatenate in module numpy.core.multiarray:\n",
      "\n",
      "concatenate(...)\n",
      "    concatenate((a1, a2, ...), axis=0)\n",
      "    \n",
      "    Join a sequence of arrays along an existing axis.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    a1, a2, ... : sequence of array_like\n",
      "        The arrays must have the same shape, except in the dimension\n",
      "        corresponding to `axis` (the first, by default).\n",
      "    axis : int, optional\n",
      "        The axis along which the arrays will be joined.  Default is 0.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    res : ndarray\n",
      "        The concatenated array.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    ma.concatenate : Concatenate function that preserves input masks.\n",
      "    array_split : Split an array into multiple sub-arrays of equal or\n",
      "                  near-equal size.\n",
      "    split : Split array into a list of multiple sub-arrays of equal size.\n",
      "    hsplit : Split array into multiple sub-arrays horizontally (column wise)\n",
      "    vsplit : Split array into multiple sub-arrays vertically (row wise)\n",
      "    dsplit : Split array into multiple sub-arrays along the 3rd axis (depth).\n",
      "    stack : Stack a sequence of arrays along a new axis.\n",
      "    hstack : Stack arrays in sequence horizontally (column wise)\n",
      "    vstack : Stack arrays in sequence vertically (row wise)\n",
      "    dstack : Stack arrays in sequence depth wise (along third dimension)\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    When one or more of the arrays to be concatenated is a MaskedArray,\n",
      "    this function will return a MaskedArray object instead of an ndarray,\n",
      "    but the input masks are *not* preserved. In cases where a MaskedArray\n",
      "    is expected as input, use the ma.concatenate function from the masked\n",
      "    array module instead.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.array([[1, 2], [3, 4]])\n",
      "    >>> b = np.array([[5, 6]])\n",
      "    >>> np.concatenate((a, b), axis=0)\n",
      "    array([[1, 2],\n",
      "           [3, 4],\n",
      "           [5, 6]])\n",
      "    >>> np.concatenate((a, b.T), axis=1)\n",
      "    array([[1, 2, 5],\n",
      "           [3, 4, 6]])\n",
      "    \n",
      "    This function will not preserve masking of MaskedArray inputs.\n",
      "    \n",
      "    >>> a = np.ma.arange(3)\n",
      "    >>> a[1] = np.ma.masked\n",
      "    >>> b = np.arange(2, 5)\n",
      "    >>> a\n",
      "    masked_array(data = [0 -- 2],\n",
      "                 mask = [False  True False],\n",
      "           fill_value = 999999)\n",
      "    >>> b\n",
      "    array([2, 3, 4])\n",
      "    >>> np.concatenate([a, b])\n",
      "    masked_array(data = [0 1 2 2 3 4],\n",
      "                 mask = False,\n",
      "           fill_value = 999999)\n",
      "    >>> np.ma.concatenate([a, b])\n",
      "    masked_array(data = [0 -- 2 2 3 4],\n",
      "                 mask = [False  True False False False False],\n",
      "           fill_value = 999999)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(np.concatenate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.]\n"
     ]
    }
   ],
   "source": [
    "print(np.ones([2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Epoch starts, Training....\n",
      "step 0 / 1250 : loss : 13.765029\n",
      "step 100 / 1250 : loss : 14.484235\n",
      "step 200 / 1250 : loss : 13.847551\n",
      "step 300 / 1250 : loss : 10.450971\n",
      "step 400 / 1250 : loss : 7.594388\n",
      "step 500 / 1250 : loss : 6.681324\n",
      "step 600 / 1250 : loss : 6.479756\n",
      "step 700 / 1250 : loss : 6.201917\n",
      "step 800 / 1250 : loss : 6.016019\n",
      "step 900 / 1250 : loss : 5.446662\n",
      "step 1000 / 1250 : loss : 5.430323\n",
      "step 1100 / 1250 : loss : 5.432162\n",
      "step 1200 / 1250 : loss : 5.328698\n",
      "precision: 0.803800\n",
      "Testing....\n",
      "Testing Accuracy: 0.891960\n",
      "1 Epoch starts, Training....\n",
      "step 0 / 1250 : loss : 1.574687\n",
      "step 100 / 1250 : loss : 4.840659\n",
      "step 200 / 1250 : loss : 5.337465\n",
      "step 300 / 1250 : loss : 4.002223\n",
      "step 400 / 1250 : loss : 3.377989\n",
      "step 500 / 1250 : loss : 3.286219\n",
      "step 600 / 1250 : loss : 3.347501\n",
      "step 700 / 1250 : loss : 3.561467\n",
      "step 800 / 1250 : loss : 3.528086\n",
      "step 900 / 1250 : loss : 3.089107\n",
      "step 1000 / 1250 : loss : 2.804906\n",
      "step 1100 / 1250 : loss : 2.924674\n",
      "step 1200 / 1250 : loss : 2.939880\n",
      "precision: 0.930560\n",
      "Testing....\n",
      "Testing Accuracy: 0.872440\n",
      "2 Epoch starts, Training....\n",
      "step 0 / 1250 : loss : 1.049529\n",
      "step 100 / 1250 : loss : 2.378785\n",
      "step 200 / 1250 : loss : 2.760617\n",
      "step 300 / 1250 : loss : 1.910799\n",
      "step 400 / 1250 : loss : 1.710098\n",
      "step 500 / 1250 : loss : 1.513580\n",
      "step 600 / 1250 : loss : 1.288736\n",
      "step 700 / 1250 : loss : 1.892904\n",
      "step 800 / 1250 : loss : 1.314955\n",
      "step 900 / 1250 : loss : 1.837270\n",
      "step 1000 / 1250 : loss : 1.408843\n",
      "step 1100 / 1250 : loss : 1.381489\n",
      "step 1200 / 1250 : loss : 1.489833\n",
      "precision: 0.969160\n",
      "Testing....\n",
      "Testing Accuracy: 0.858720\n",
      "3 Epoch starts, Training....\n",
      "step 0 / 1250 : loss : 0.718857\n",
      "step 100 / 1250 : loss : 0.997779\n",
      "step 200 / 1250 : loss : 0.599790\n",
      "step 300 / 1250 : loss : 0.860808\n",
      "step 400 / 1250 : loss : 1.404219\n",
      "step 500 / 1250 : loss : 0.815656\n",
      "step 600 / 1250 : loss : 1.094007\n",
      "step 700 / 1250 : loss : 1.136194\n",
      "step 800 / 1250 : loss : 0.684115\n",
      "step 900 / 1250 : loss : 1.042454\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-0b23edc2d0e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_out_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             '''\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect_num_step\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mloss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wang/tensorflow_dl/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 717\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    718\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wang/tensorflow_dl/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 915\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    916\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wang/tensorflow_dl/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 965\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/wang/tensorflow_dl/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    970\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    973\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wang/tensorflow_dl/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    952\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m    953\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default(), tf.Session() as sess:\n",
    "    input_placeholder, label_placeholder = add_placeholders()\n",
    "    vocab_size = max_features\n",
    "    #Embed layer\n",
    "    inputs = add_embed_layer(vocab_size, input_placeholder)\n",
    "    #CNN layer\n",
    "    W_cnn = tf.Variable(initial_value =tf.truncated_normal(shape=[5,50, 64], stddev=0.1))\n",
    "    b_cnn = tf.Variable(initial_value=tf.truncated_normal(shape=[64], stddev=0.1))\n",
    "    cnn1_out = tf.nn.relu(conv1d(inputs, W_cnn) + b_cnn)\n",
    "    #Pooling layer\n",
    "    #pool_out: [batch_size, height/2, channels]\n",
    "    \n",
    "    pool_out = max_pool1d(cnn1_out)\n",
    "    pool_out_flat = tf.reshape(pool_out, [-1, 400*64])\n",
    "    \n",
    "    ##Fully connected layer\n",
    "    W_fc = tf.Variable(initial_value=tf.truncated_normal(shape=[400*64, 100], stddev=0.1))\n",
    "    b_fc = tf.Variable(initial_value=tf.truncated_normal(shape=[100], stddev=0.1))\n",
    "    fc_out = tf.nn.relu(tf.matmul(pool_out_flat, W_fc) + b_fc)    \n",
    "    ##sigmoid layer\n",
    "    W_classifier = tf.Variable(initial_value=tf.truncated_normal(shape=[100, 1], stddev=0.1))\n",
    "    b_classifier = tf.Variable(initial_value=tf.truncated_normal(shape=[1], stddev=0.1))\n",
    "    ##\n",
    "    y_pred = tf.squeeze(tf.matmul(fc_out, W_classifier) + b_classifier)\n",
    "    y_pred_sigmoid = tf.nn.sigmoid(y_pred)\n",
    "    ##\n",
    "    correct_num = evaluation(y_pred_sigmoid, label_placeholder)\n",
    "    \n",
    "    loss = tf.nn.sigmoid_cross_entropy_with_logits(y_pred, label_placeholder)\n",
    "    \n",
    "    train_op = add_train_op(loss)\n",
    "    \n",
    "    #state_step = initial_state\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    \n",
    "    for epoch in range(max_epochs):\n",
    "        print('%d Epoch starts, Training....' %(epoch))\n",
    "        mean_loss = []\n",
    "        total_correct_num = 0\n",
    "        for step in range(len(X_train) // batch_size):\n",
    "\n",
    "            input_batch = X_train[step*batch_size:(step+1)*batch_size, :]\n",
    "            label_batch = y_train[step*batch_size:(step+1)*batch_size]\n",
    "            \n",
    "           \n",
    "            \n",
    "            feed = {input_placeholder:input_batch, label_placeholder:label_batch}\n",
    "            '''\n",
    "            inputs_step, cnn1_out_step, pool_out_step = sess.run([inputs, cnn1_out, pool_out], feed)\n",
    "            print(inputs_step.shape)\n",
    "            print(cnn1_out_step.shape)\n",
    "            print(pool_out_step.shape)\n",
    "            '''\n",
    "            _, y_pred_step, loss_step, correct_num_step= sess.run([train_op, y_pred, loss, correct_num], feed)\n",
    "            \n",
    "            loss_step = np.sum(loss_step)\n",
    "            mean_loss.append(loss_step)\n",
    "            total_correct_num += correct_num_step\n",
    "            \n",
    "            if step % 100 == 0:\n",
    "                print('step %d / %d : loss : %f' %(step, len(X_train) // batch_size, np.mean(mean_loss)))\n",
    "                mean_loss = []\n",
    "            \n",
    "        print('precision: %f' %(total_correct_num/len(X_train)))\n",
    "        print('Testing....')\n",
    "        do_evaluation(sess, X_test, y_test)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function dropout in module tensorflow.python.ops.nn_ops:\n",
      "\n",
      "dropout(x, keep_prob, noise_shape=None, seed=None, name=None)\n",
      "    Computes dropout.\n",
      "    \n",
      "    With probability `keep_prob`, outputs the input element scaled up by\n",
      "    `1 / keep_prob`, otherwise outputs `0`.  The scaling is so that the expected\n",
      "    sum is unchanged.\n",
      "    \n",
      "    By default, each element is kept or dropped independently.  If `noise_shape`\n",
      "    is specified, it must be\n",
      "    [broadcastable](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "    to the shape of `x`, and only dimensions with `noise_shape[i] == shape(x)[i]`\n",
      "    will make independent decisions.  For example, if `shape(x) = [k, l, m, n]`\n",
      "    and `noise_shape = [k, 1, 1, n]`, each batch and channel component will be\n",
      "    kept independently and each row and column will be kept or not kept together.\n",
      "    \n",
      "    Args:\n",
      "      x: A tensor.\n",
      "      keep_prob: A scalar `Tensor` with the same type as x. The probability\n",
      "        that each element is kept.\n",
      "      noise_shape: A 1-D `Tensor` of type `int32`, representing the\n",
      "        shape for randomly generated keep/drop flags.\n",
      "      seed: A Python integer. Used to create random seeds. See\n",
      "        [`set_random_seed`](../../api_docs/python/constant_op.md#set_random_seed)\n",
      "        for behavior.\n",
      "      name: A name for this operation (optional).\n",
      "    \n",
      "    Returns:\n",
      "      A Tensor of the same shape of `x`.\n",
      "    \n",
      "    Raises:\n",
      "      ValueError: If `keep_prob` is not in `(0, 1]`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.nn.dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-151-8d2226d80f7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_placeholder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mtrain_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_train_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m#state_step = initial_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-168cc6090ea8>\u001b[0m in \u001b[0;36madd_train_op\u001b[0;34m(loss)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## add training op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0madd_train_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wang/tensorflow_dl/local/lib/python2.7/site-packages/tensorflow/python/training/optimizer.pyc\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, global_step, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, name, grad_loss)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0maggregation_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation_method\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         grad_loss=grad_loss)\n\u001b[0m\u001b[1;32m    197\u001b[0m     return self.apply_gradients(grads_and_vars, global_step=global_step,\n\u001b[1;32m    198\u001b[0m                                 name=name)\n",
      "\u001b[0;32m/home/wang/tensorflow_dl/local/lib/python2.7/site-packages/tensorflow/python/training/optimizer.pyc\u001b[0m in \u001b[0;36mcompute_gradients\u001b[0;34m(self, loss, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, grad_loss)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mgate_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgate_gradients\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGATE_OP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0maggregation_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation_method\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         colocate_gradients_with_ops=colocate_gradients_with_ops)\n\u001b[0m\u001b[1;32m    254\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgate_gradients\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGATE_GRAPH\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m       \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontrol_flow_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wang/tensorflow_dl/local/lib/python2.7/site-packages/tensorflow/python/ops/gradients.pyc\u001b[0m in \u001b[0;36mgradients\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method)\u001b[0m\n\u001b[1;32m    474\u001b[0m                 \u001b[0;31m# If grad_fn was found, do not use SymbolicGradient even for\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m                 \u001b[0;31m# functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m                 \u001b[0min_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_AsList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m                 \u001b[0;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wang/tensorflow_dl/local/lib/python2.7/site-packages/tensorflow/python/ops/math_grad.pyc\u001b[0m in \u001b[0;36m_AddGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    497\u001b[0m   \u001b[0msx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m   \u001b[0msy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m   \u001b[0mrx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_broadcast_gradient_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m   return (array_ops.reshape(math_ops.reduce_sum(grad, rx), sx),\n\u001b[1;32m    501\u001b[0m           array_ops.reshape(math_ops.reduce_sum(grad, ry), sy))\n",
      "\u001b[0;32m/home/wang/tensorflow_dl/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.pyc\u001b[0m in \u001b[0;36m_broadcast_gradient_args\u001b[0;34m(s0, s1, name)\u001b[0m\n\u001b[1;32m    364\u001b[0m   \"\"\"\n\u001b[1;32m    365\u001b[0m   result = _op_def_lib.apply_op(\"BroadcastGradientArgs\", s0=s0, s1=s1,\n\u001b[0;32m--> 366\u001b[0;31m                                 name=name)\n\u001b[0m\u001b[1;32m    367\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0m_BroadcastGradientArgsOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wang/tensorflow_dl/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.pyc\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    701\u001b[0m           op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    702\u001b[0m                            \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m                            op_def=op_def)\n\u001b[0m\u001b[1;32m    704\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m           return _Restructure(ops.convert_n_to_tensor(outputs),\n",
      "\u001b[0;32m/home/wang/tensorflow_dl/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2334\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[1;32m   2335\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2336\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2337\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2338\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wang/tensorflow_dl/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1723\u001b[0m       raise RuntimeError(\"No shape function registered for standard op: %s\"\n\u001b[1;32m   1724\u001b[0m                          % op.type)\n\u001b[0;32m-> 1725\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1726\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1727\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m/home/wang/tensorflow_dl/local/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.pyc\u001b[0m in \u001b[0;36m_BroadcastGradientArgsShape\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1957\u001b[0m   \u001b[0;31m# TODO(mrry): Implement constant_value for BroadcastGradientArgs?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1958\u001b[0m   \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_has_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1959\u001b[0;31m   \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_has_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1960\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wang/tensorflow_dl/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36minputs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1465\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1466\u001b[0m     \u001b[0;34m\"\"\"The list of `Tensor` objects representing the data inputs of this op.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1467\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mOperation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_InputList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1469\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default(), tf.Session() as sess:\n",
    "    input_placeholder, label_placeholder = add_placeholders()\n",
    "    initial_state_placeholder = tf.placeholder(tf.float32)\n",
    "    vocab_size = max_features\n",
    "    inputs = add_embed_layer(vocab_size, input_placeholder)\n",
    "    \n",
    "    ##initial state\n",
    "    cell = add_rnn_model(hidden_size, num_steps)\n",
    "    initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "\n",
    "    # state is the final state\n",
    "    outputs, state = tf.nn.rnn(cell, inputs, initial_state=initial_state)\n",
    "    #add projection layer\n",
    "    W = tf.get_variable('Weights', shape=[hidden_size, 1])\n",
    "    b = tf.get_variable('Bias', shape = [1])\n",
    "    \n",
    "    y_pred = tf.squeeze(tf.matmul(outputs[-1], W) )\n",
    "    \n",
    "    y_pred_sigmoid = tf.sigmoid(y_pred)\n",
    "    \n",
    "    correct_num = evaluation(y_pred_sigmoid, label_placeholder)\n",
    "    \n",
    "    loss = tf.nn.sigmoid_cross_entropy_with_logits(y_pred, label_placeholder)\n",
    "    \n",
    "    train_op = add_train_op(loss)\n",
    "    \n",
    "    #state_step = initial_state\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        print('%d Epoch starts, Training....' %(epoch))\n",
    "        mean_loss = []\n",
    "        total_correct_num = 0\n",
    "        for step in range(len(X_train) // batch_size):\n",
    "            # generate the data feed dict\n",
    "            if step == 0:\n",
    "                init_state = sess.run([initial_state])\n",
    "            else:\n",
    "                init_state = state_step[-1]\n",
    "            input_batch = X_train[step*batch_size:(step+1)*batch_size, :]\n",
    "            label_batch = y_train[step*batch_size:(step+1)*batch_size]\n",
    "            \n",
    "            '''\n",
    "            feed = create_feed_dict(input_placeholder, input_batch, \n",
    "                                    label_placeholder, label_batch, \n",
    "                                    initial_state_placeholder, initial_state)\n",
    "            '''\n",
    "            feed = {input_placeholder:input_batch, label_placeholder:label_batch, initial_state_placeholder:init_state }\n",
    "            _, state_step , y_pred_step, loss_step, correct_num_step= sess.run([train_op, state, y_pred, loss, correct_num], feed)\n",
    "            \n",
    "            loss_step = np.sum(loss_step)\n",
    "            mean_loss.append(loss_step)\n",
    "            total_correct_num += correct_num_step\n",
    "            \n",
    "            if step % 100 == 0:\n",
    "                print('step %d / %d : loss : %f' %(step, len(X_train) // batch_size, np.mean(mean_loss)))\n",
    "                mean_loss = []\n",
    "            do_evaluation(sess, X_test, y_test)\n",
    "        print('precision: %f' %(total_correct_num/len(X_train)))\n",
    "        print('Testing....')\n",
    "        do_evaluation(sess, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function sigmoid_cross_entropy_with_logits in module tensorflow.python.ops.nn:\n",
      "\n",
      "sigmoid_cross_entropy_with_logits(logits, targets, name=None)\n",
      "    Computes sigmoid cross entropy given `logits`.\n",
      "    \n",
      "    Measures the probability error in discrete classification tasks in which each\n",
      "    class is independent and not mutually exclusive.  For instance, one could\n",
      "    perform multilabel classification where a picture can contain both an elephant\n",
      "    and a dog at the same time.\n",
      "    \n",
      "    For brevity, let `x = logits`, `z = targets`.  The logistic loss is\n",
      "    \n",
      "          z * -log(sigmoid(x)) + (1 - z) * -log(1 - sigmoid(x))\n",
      "        = z * -log(1 / (1 + exp(-x))) + (1 - z) * -log(exp(-x) / (1 + exp(-x)))\n",
      "        = z * log(1 + exp(-x)) + (1 - z) * (-log(exp(-x)) + log(1 + exp(-x)))\n",
      "        = z * log(1 + exp(-x)) + (1 - z) * (x + log(1 + exp(-x))\n",
      "        = (1 - z) * x + log(1 + exp(-x))\n",
      "        = x - x * z + log(1 + exp(-x))\n",
      "    \n",
      "    For x < 0, to avoid overflow in exp(-x), we reformulate the above\n",
      "    \n",
      "          x - x * z + log(1 + exp(-x))\n",
      "        = log(exp(x)) - x * z + log(1 + exp(-x))\n",
      "        = - x * z + log(1 + exp(x))\n",
      "    \n",
      "    Hence, to ensure stability and avoid overflow, the implementation uses this\n",
      "    equivalent formulation\n",
      "    \n",
      "        max(x, 0) - x * z + log(1 + exp(-abs(x)))\n",
      "    \n",
      "    `logits` and `targets` must have the same type and shape.\n",
      "    \n",
      "    Args:\n",
      "      logits: A `Tensor` of type `float32` or `float64`.\n",
      "      targets: A `Tensor` of the same type and shape as `logits`.\n",
      "      name: A name for the operation (optional).\n",
      "    \n",
      "    Returns:\n",
      "      A `Tensor` of the same shape as `logits` with the componentwise\n",
      "      logistic losses.\n",
      "    \n",
      "    Raises:\n",
      "      ValueError: If `logits` and `targets` do not have the same shape.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.nn.sigmoid_cross_entropy_with_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "help(tf.nn.rnn_cell.BasicLSTMCell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "help(tf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Create input data\n",
    "#X = np.random.randn(2, 10, 8)\n",
    "X= tf.random_uniform(dtype=tf.float,shape=[2,10,8])\n",
    "# The second example is of length 6 \n",
    "#X[1,6,:] = 0\n",
    "#X_lengths = [10, 6]\n",
    "X_new = []\n",
    "for index in range(8):\n",
    "    X_new.append(X[:,:,index])\n",
    "#X_new = (tf.squeeze(X[0,:,:]),tf.squeeze(X[1,:,:]))\n",
    "cell = tf.nn.rnn_cell.LSTMCell(num_units=64, state_is_tuple=True)\n",
    "#cell = tf.nn.rnn_cell.MultiRNNCell([lstm_cell] * 10)\n",
    "\n",
    "outputs, last_states = tf.nn.rnn(\n",
    "    cell=cell,\n",
    "    dtype=tf.float64,\n",
    "    sequence_length=X_lengths,\n",
    "    inputs=X_new)\n",
    "\n",
    "result = tf.contrib.learn.run_n(\n",
    "    {\"outputs\": outputs, \"last_states\": last_states},\n",
    "    n=1,\n",
    "    feed_dict=None)\n",
    "\n",
    "assert result[0][\"outputs\"].shape == (2, 10, 64)\n",
    "print(result[0][\"outputs\"])\n",
    "\n",
    "# Outputs for the second example past past length 6 should be 0\n",
    "assert (result[0][\"outputs\"][1,7,:] == np.zeros(cell.output_size)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
